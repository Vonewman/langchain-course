{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562f9b49-0fe8-4ee6-895f-78ceae986a8c",
   "metadata": {},
   "source": [
    "# Exploring the World of Language Models: LLMs vs Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23840e6e-71a3-4c6f-ba2a-a775034d17af",
   "metadata": {},
   "source": [
    "## Understanding LLMs and Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e695381-283f-445e-b1d6-ca01dc0f14f2",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9700fdc9-6dfa-4370-9e19-769c3ade28c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wireless Audio Solutions\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=[\"product\"],\n",
    "  template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print( chain.run(\"wireless headphones\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ffb58d-5ede-4641-b03a-eb488159240e",
   "metadata": {},
   "source": [
    "### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f06f91-4672-4a28-a6d3-65c1fb0cbc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "  HumanMessage,\n",
    "  SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "messages = [\n",
    "\tSystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "\tHumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3855bc-408c-4998-a76e-a50289777003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text=\"J'adore la programmation.\", generation_info=None, message=AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False))], [ChatGeneration(text='I like programming.', generation_info=None, message=AIMessage(content='I like programming.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 65, 'completion_tokens': 12, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo'} run=RunInfo(run_id=UUID('2f90b484-ebf7-4a51-8fe7-dd501f125804'))\n"
     ]
    }
   ],
   "source": [
    "batch_messages = [\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "  ],\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates French to English.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: J'aime la programmation.\")\n",
    "  ],\n",
    "]\n",
    "print( chat.generate(batch_messages) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7d728-2a6e-4f66-a5fe-a482ee085197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
